{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a106713f",
   "metadata": {},
   "source": [
    "## Create Occurrence Data Set including eventDate\n",
    "\n",
    "### Store GBIF Occurrence Data Set locally\n",
    "\n",
    "For Meise Botanic Garden Herbarium (BR) see example data set <https://doi.org/10.15468/dl.ax9zkh>. We saved all of it into the local data directory `data/Meise_doi-10.15468-dl.ax9zkh/`:\n",
    "- The CSV data file is +1GB large—please download it first (**it will not be in the official GitHub documentation**) or change the code here to read your special input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7530a19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All right, expected data found:\n",
      "- GBIF data found in data/Meise_doi-10.15468-dl.ax9zkh \n",
      "- Results will later be written to data/Meise_doi-10.15468-dl.ax9zkh/occurrence_recordedBy_eventDate_occurrenceIDs_20230830.tsv\n"
     ]
    }
   ],
   "source": [
    "import os, time, pprint\n",
    "\n",
    "gbif_dataset_path=\"data/Meise_doi-10.15468-dl.ax9zkh\"\n",
    "gbif_occurrence_source_file=\"0165208-230224095556074.csv\" # was \\t separated; expect CSV to have comma not tab as separator character(!)\n",
    "\n",
    "# join file name dynamically for saving results\n",
    "this_output_tabdata_file=os.path.join(\n",
    "    gbif_dataset_path, (\n",
    "        \"occurrence_recordedBy_eventDate_occurrenceIDs_%s.tsv\" % \n",
    "        # '20230726'\n",
    "        time.strftime('%Y%m%d')\n",
    "    )\n",
    ")\n",
    "# use static file name for saving\n",
    "# this_output_tabdata_file=data/Meise_doi-10.15468-dl.ax9zkh/occurrence_recordedBy_occurrenceIDs_20230524.tsv\n",
    "\n",
    "if not os.path.exists(gbif_dataset_path):\n",
    "    print(\"Where is the folder of are GBIF occurrence data?\", gbif_dataset_path, \"not found\")\n",
    "    print(\"Recommendation is use a subfolder, e.g. “data/Meise_doi-10.15468-dl.ax9zkh”\")\n",
    "else:\n",
    "    print(\"All right, expected data found:\\n- GBIF data found in\", gbif_dataset_path ,\"\\n- Results will later be written to\", this_output_tabdata_file)\n",
    "    if not os.path.exists(os.path.join(gbif_dataset_path, gbif_occurrence_source_file)):\n",
    "        print(\"What data source file is the right one? The expected CSV-file\", gbif_occurrence_source_file, \"was not found.\")\n",
    "        print(\"Set the file in Python variable 'gbif_occurrence_source_file' to the correct file name.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e93e228",
   "metadata": {},
   "source": [
    "### Read GBIF Occurrence Data\n",
    "\n",
    "Get `recordedBy` and `created` of `gbif_occurrence_source_file=0165208-230224095556074.csv` and look into the data first, data columns aso. …"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7db47f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['gbifID', 'datasetKey', 'occurrenceID', 'kingdom', 'phylum', 'class',\n",
      "       'order', 'family', 'genus', 'species', 'infraspecificEpithet',\n",
      "       'taxonRank', 'scientificName', 'verbatimScientificName',\n",
      "       'verbatimScientificNameAuthorship', 'countryCode', 'locality',\n",
      "       'stateProvince', 'occurrenceStatus', 'individualCount',\n",
      "       'publishingOrgKey', 'decimalLatitude', 'decimalLongitude',\n",
      "       'coordinateUncertaintyInMeters', 'coordinatePrecision', 'elevation',\n",
      "       'elevationAccuracy', 'depth', 'depthAccuracy', 'eventDate', 'day',\n",
      "       'month', 'year', 'taxonKey', 'speciesKey', 'basisOfRecord',\n",
      "       'institutionCode', 'collectionCode', 'catalogNumber', 'recordNumber',\n",
      "       'identifiedBy', 'dateIdentified', 'license', 'rightsHolder',\n",
      "       'recordedBy', 'typeStatus', 'establishmentMeans', 'lastInterpreted',\n",
      "       'mediaType', 'issue'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # to read data\n",
    "\n",
    "# Reading all at once does not work to read 1GB of data yet\n",
    "occurrences = pd.read_csv(\n",
    "    os.path.join(gbif_dataset_path, gbif_occurrence_source_file), sep=\"\\t\", low_memory=False,\n",
    "    nrows=1\n",
    ")\n",
    "\n",
    "pprint.pprint(occurrences.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19d3a133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occurrenceID</th>\n",
       "      <th>eventDate</th>\n",
       "      <th>recordedBy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.botanicalcollections.be/specimen/BR...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lebrun J.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.botanicalcollections.be/specimen/BR...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jurion F.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.botanicalcollections.be/specimen/BR...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dubois H.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.botanicalcollections.be/specimen/BR...</td>\n",
       "      <td>1960-04-16T00:00:00</td>\n",
       "      <td>Hendrickx F.L.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.botanicalcollections.be/specimen/BR...</td>\n",
       "      <td>1921-05-01T00:00:00</td>\n",
       "      <td>Claessens J.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        occurrenceID            eventDate  \\\n",
       "0  http://www.botanicalcollections.be/specimen/BR...                  NaN   \n",
       "1  http://www.botanicalcollections.be/specimen/BR...                  NaN   \n",
       "2  http://www.botanicalcollections.be/specimen/BR...                  NaN   \n",
       "3  http://www.botanicalcollections.be/specimen/BR...  1960-04-16T00:00:00   \n",
       "4  http://www.botanicalcollections.be/specimen/BR...  1921-05-01T00:00:00   \n",
       "\n",
       "       recordedBy  \n",
       "0       Lebrun J.  \n",
       "1       Jurion F.  \n",
       "2       Dubois H.  \n",
       "3  Hendrickx F.L.  \n",
       "4    Claessens J.  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just see the first rows\n",
    "occurrences = pd.read_csv(\n",
    "    os.path.join(gbif_dataset_path, gbif_occurrence_source_file), sep=\"\\t\", low_memory=False,\n",
    "    usecols=[\"occurrenceID\", \"recordedBy\", \"eventDate\"],\n",
    "    nrows=50 # read all data results in memory kill\n",
    ")\n",
    "occurrences.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b82390",
   "metadata": {},
   "source": [
    "We follow <https://towardsdatascience.com/tips-and-tricks-for-loading-large-csv-files-into-pandas-dataframes-part-2-5fc02fc4e3ab> and filter for having an occourrenceID.\n",
    "\n",
    "For large data sets it is better to read it defining a “chunksize” (because otherwise the processor would read all at once and gets stuck):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83a954c6-fb0c-48ff-a79a-d30508f893a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read large data as chunk 0.00852656364440918 seconds\n",
      "filter having occurrenceID: (100000, 3)\n",
      "filter having occurrenceID: (100000, 3)\n",
      "filter having occurrenceID: (100000, 3)\n",
      "filter having occurrenceID: (100000, 3)\n",
      "filter having occurrenceID: (100000, 3)\n",
      "filter having occurrenceID: (100000, 3)\n",
      "filter having occurrenceID: (100000, 3)\n",
      "filter having occurrenceID: (100000, 3)\n",
      "filter having occurrenceID: (100000, 3)\n",
      "filter having occurrenceID: (100000, 3)\n",
      "filter having occurrenceID: (100000, 3)\n",
      "filter having occurrenceID: (100000, 3)\n",
      "filter having occurrenceID: (100000, 3)\n",
      "filter having occurrenceID: (100000, 3)\n",
      "filter having occurrenceID: (100000, 3)\n",
      "filter having occurrenceID: (100000, 3)\n",
      "filter having occurrenceID: (100000, 3)\n",
      "filter having occurrenceID: (100000, 3)\n",
      "filter having occurrenceID: (100000, 3)\n",
      "filter having occurrenceID: (100000, 3)\n",
      "filter having occurrenceID: (100000, 3)\n",
      "filter having occurrenceID: (100000, 3)\n",
      "filter having occurrenceID: (100000, 3)\n",
      "filter having occurrenceID: (100000, 3)\n",
      "filter having occurrenceID: (100000, 3)\n",
      "filter having occurrenceID: (100000, 3)\n",
      "filter having occurrenceID: (100000, 3)\n",
      "filter having occurrenceID: (76174, 3)\n",
      "process data having only occurrenceID took 37.965131759643555  seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occurrenceID</th>\n",
       "      <th>eventDate</th>\n",
       "      <th>recordedBy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.botanicalcollections.be/specimen/BR...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lebrun J.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.botanicalcollections.be/specimen/BR...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jurion F.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.botanicalcollections.be/specimen/BR...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dubois H.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.botanicalcollections.be/specimen/BR...</td>\n",
       "      <td>1960-04-16T00:00:00</td>\n",
       "      <td>Hendrickx F.L.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.botanicalcollections.be/specimen/BR...</td>\n",
       "      <td>1921-05-01T00:00:00</td>\n",
       "      <td>Claessens J.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        occurrenceID            eventDate  \\\n",
       "0  http://www.botanicalcollections.be/specimen/BR...                  NaN   \n",
       "1  http://www.botanicalcollections.be/specimen/BR...                  NaN   \n",
       "2  http://www.botanicalcollections.be/specimen/BR...                  NaN   \n",
       "3  http://www.botanicalcollections.be/specimen/BR...  1960-04-16T00:00:00   \n",
       "4  http://www.botanicalcollections.be/specimen/BR...  1921-05-01T00:00:00   \n",
       "\n",
       "       recordedBy  \n",
       "0       Lebrun J.  \n",
       "1       Jurion F.  \n",
       "2       Dubois H.  \n",
       "3  Hendrickx F.L.  \n",
       "4    Claessens J.  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starttime = time.time()\n",
    "\n",
    "chunks_occurrences = pd.read_csv(\n",
    "    os.path.join(gbif_dataset_path, gbif_occurrence_source_file), sep=\"\\t\", low_memory=False,\n",
    "    usecols=[\"occurrenceID\", \"recordedBy\", \"eventDate\"],\n",
    "    chunksize=100000\n",
    ")\n",
    "\n",
    "print(\"read large data as chunk\", time.time() - starttime, 'seconds')\n",
    "\n",
    "def filter_having_occurrenceID(df):\n",
    "    df = df[df.occurrenceID.notnull()]\n",
    "    print(\"filter having occurrenceID: \" + str(df.shape))\n",
    "    # print(df.shape)\n",
    "    return df\n",
    "\n",
    "starttime = time.time()\n",
    "chunk_list = [] # used for storing dataframes\n",
    "for chunk in chunks_occurrences:\n",
    "    # each chunk is a dataframe\n",
    "    # perform data filtering\n",
    "    filtered_chunk = filter_having_occurrenceID(chunk)\n",
    "    # Once the data filtering is done, append the filtered chunk to list\n",
    "    chunk_list.append(filtered_chunk)\n",
    "\n",
    "# concat all the dfs in the list in\n",
    "occurrences = pd.concat(chunk_list)\n",
    "\n",
    "print(\"process data having only occurrenceID took\", time.time() - starttime, ' seconds')\n",
    "# occurrences.dropna(subset=['eventDate'], inplace=True) # test to keep NA for eventDate\n",
    "occurrences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d8d524b-84ce-4346-86d6-092ee6bdddb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occurrenceID</th>\n",
       "      <th>eventDate</th>\n",
       "      <th>recordedBy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.botanicalcollections.be/specimen/BR...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Lebrun J.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.botanicalcollections.be/specimen/BR...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Jurion F.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.botanicalcollections.be/specimen/BR...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Dubois H.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.botanicalcollections.be/specimen/BR...</td>\n",
       "      <td>1960-04-16 00:00:00.000</td>\n",
       "      <td>Hendrickx F.L.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.botanicalcollections.be/specimen/BR...</td>\n",
       "      <td>1921-05-01 00:00:00.000</td>\n",
       "      <td>Claessens J.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        occurrenceID                eventDate  \\\n",
       "0  http://www.botanicalcollections.be/specimen/BR...                      NaT   \n",
       "1  http://www.botanicalcollections.be/specimen/BR...                      NaT   \n",
       "2  http://www.botanicalcollections.be/specimen/BR...                      NaT   \n",
       "3  http://www.botanicalcollections.be/specimen/BR...  1960-04-16 00:00:00.000   \n",
       "4  http://www.botanicalcollections.be/specimen/BR...  1921-05-01 00:00:00.000   \n",
       "\n",
       "       recordedBy  \n",
       "0       Lebrun J.  \n",
       "1       Jurion F.  \n",
       "2       Dubois H.  \n",
       "3  Hendrickx F.L.  \n",
       "4    Claessens J.  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Convert to date/time\n",
    "#\n",
    "# occurrences.dtypes\n",
    "#   occurrenceID    object\n",
    "#   recordedBy      object\n",
    "#   eventDate       object\n",
    "#   dtype: object\n",
    "\n",
    "# df['dates'] = pd.to_datetime(df['dates'], format='%Y%m%d')\n",
    "# pd.to_datetime(\"12/29/2020  9:09:37 PM\", utc=True)\n",
    "# pd.to_datetime(\"1904-07-01T00:00:00\", utc=True)\n",
    "\n",
    "# occurrences['eventDate']= pd.to_datetime(occurrences.eventDate, utc=True) # Out of bounds nanosecond timestamp: 1652-01-01T00:00:00\n",
    "#  because date nanoseconds range limitations of pandas, see https://stackoverflow.com/a/69507200/1240387\n",
    "#  work around: use datetime\n",
    "#  occurrences['eventDate'] = occurrences['eventDate'].apply(lambda x: datetime.strptime(x,'%Y-%m-%dT%H:%M:%S') if type(x)==str else pd.NaT)\n",
    "# or using pd.Periode(…)\n",
    "occurrences['eventDate'] = occurrences['eventDate'].apply(lambda x: pd.Period(x, freq='ms'))\n",
    "occurrences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8770b7e2-16a3-4e96-8b9c-b48feaf3e980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "occurrenceID       object\n",
       "eventDate       period[L]\n",
       "recordedBy         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "occurrences.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2790fe65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recordedBy</th>\n",
       "      <th>occurrenceID_count</th>\n",
       "      <th>occurrenceID_firstsample</th>\n",
       "      <th>eventDate_mean</th>\n",
       "      <th>eventDate_min</th>\n",
       "      <th>eventDate_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'Discovery' Exped.</td>\n",
       "      <td>1</td>\n",
       "      <td>http://www.botanicalcollections.be/specimen/BR...</td>\n",
       "      <td>1934-04-01 00:00:00.000</td>\n",
       "      <td>1934-04-01 00:00:00.000</td>\n",
       "      <td>1934-04-01 00:00:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Discovery' Exped. 1934-35</td>\n",
       "      <td>3</td>\n",
       "      <td>http://www.botanicalcollections.be/specimen/BR...</td>\n",
       "      <td>1934-12-28 16:00:00.000</td>\n",
       "      <td>1934-12-14 00:00:00.000</td>\n",
       "      <td>1935-01-20 00:00:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'Discovery' Expedition</td>\n",
       "      <td>1</td>\n",
       "      <td>http://www.botanicalcollections.be/specimen/BR...</td>\n",
       "      <td>1934-01-01 00:00:00.000</td>\n",
       "      <td>1934-01-01 00:00:00.000</td>\n",
       "      <td>1934-01-01 00:00:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'Engledow in Bolton J.J.'</td>\n",
       "      <td>2</td>\n",
       "      <td>http://www.botanicalcollections.be/specimen/BR...</td>\n",
       "      <td>1998-07-08 12:00:00.000</td>\n",
       "      <td>1998-07-08 00:00:00.000</td>\n",
       "      <td>1998-07-09 00:00:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'Engledow in Bolton'</td>\n",
       "      <td>2</td>\n",
       "      <td>http://www.botanicalcollections.be/specimen/BR...</td>\n",
       "      <td>1998-07-08 00:00:00.000</td>\n",
       "      <td>1998-07-08 00:00:00.000</td>\n",
       "      <td>1998-07-08 00:00:00.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   recordedBy  occurrenceID_count  \\\n",
       "0          'Discovery' Exped.                   1   \n",
       "1  'Discovery' Exped. 1934-35                   3   \n",
       "2      'Discovery' Expedition                   1   \n",
       "3   'Engledow in Bolton J.J.'                   2   \n",
       "4        'Engledow in Bolton'                   2   \n",
       "\n",
       "                            occurrenceID_firstsample           eventDate_mean  \\\n",
       "0  http://www.botanicalcollections.be/specimen/BR...  1934-04-01 00:00:00.000   \n",
       "1  http://www.botanicalcollections.be/specimen/BR...  1934-12-28 16:00:00.000   \n",
       "2  http://www.botanicalcollections.be/specimen/BR...  1934-01-01 00:00:00.000   \n",
       "3  http://www.botanicalcollections.be/specimen/BR...  1998-07-08 12:00:00.000   \n",
       "4  http://www.botanicalcollections.be/specimen/BR...  1998-07-08 00:00:00.000   \n",
       "\n",
       "             eventDate_min            eventDate_max  \n",
       "0  1934-04-01 00:00:00.000  1934-04-01 00:00:00.000  \n",
       "1  1934-12-14 00:00:00.000  1935-01-20 00:00:00.000  \n",
       "2  1934-01-01 00:00:00.000  1934-01-01 00:00:00.000  \n",
       "3  1998-07-08 00:00:00.000  1998-07-09 00:00:00.000  \n",
       "4  1998-07-08 00:00:00.000  1998-07-08 00:00:00.000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group and aggregate data: \n",
    "\n",
    "occurrences_unique=occurrences.groupby(['recordedBy']).agg(\n",
    "    occurrenceID_count= ('occurrenceID', 'count'), # use count function\n",
    "    occurrenceID_firstsample=('occurrenceID', lambda x: list(x)[0]) # custom function, to get the first entry\n",
    "    , eventDate_mean=('eventDate', 'mean')\n",
    "    , eventDate_min=('eventDate', 'min')\n",
    "    , eventDate_max=('eventDate', 'max')\n",
    ").reset_index()\n",
    "\n",
    "occurrences_unique.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f999e270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write these tabbed data into data/Meise_doi-10.15468-dl.ax9zkh/occurrence_recordedBy_eventDate_occurrenceIDs_20230830.tsv\n"
     ]
    }
   ],
   "source": [
    "print(\"Write these tabbed data into\", this_output_tabdata_file)\n",
    "\n",
    "occurrences_unique.to_csv(this_output_tabdata_file, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1c0f0c",
   "metadata": {},
   "source": [
    "## Parsing with dwcagent_bin\n",
    "\n",
    "Dependency Ruby Gem package <https://libraries.io/rubygems/dwc_agent> has to be installed and Ruby itself.\n",
    "\n",
    "You can use the ruby script in `bin/agent_parse4tsv.rb` and change the file(s) for input and output:\n",
    "```bash\n",
    "cd bin\n",
    "ruby agent_parse4tsv.rb --help # display usage and help of the script\n",
    "\n",
    "ruby agent_parse4tsv.rb \\\n",
    "  --input  ../data/Meise_doi-10.15468-dl.ax9zkh/occurrence_recordedBy_eventDate_occurrenceIDs_20230830.tsv \\\n",
    "  --output ../data/Meise_doi-10.15468-dl.ax9zkh/occurrence_recordedBy_eventDate_occurrenceIDs_20230830_parsed.tsv\n",
    "\n",
    "# or if you want to measure how fast it parses use time … — add writing a logfile of skipped names\n",
    "time ruby agent_parse4tsv.rb --logfile \\\n",
    "  --input  ../data/Meise_doi-10.15468-dl.ax9zkh/occurrence_recordedBy_eventDate_occurrenceIDs_20230830.tsv \\\n",
    "  --output ../data/Meise_doi-10.15468-dl.ax9zkh/occurrence_recordedBy_eventDate_occurrenceIDs_20230830_parsed.tsv\n",
    "#   Now:\n",
    "#   - read data from ../data/Meise_doi-10.15468-dl.ax9zkh/occurrence_recordedBy_eventDate_occurrenceIDs_20230830.tsv\n",
    "#   - write data to  ../data/Meise_doi-10.15468-dl.ax9zkh/occurrence_recordedBy_eventDate_occurrenceIDs_20230830_parsed.tsv\n",
    "#   - write log of skipped names into output directory as well: occurrence_recordedBy_eventDate_occurrenceIDs_20230830_parsed.tsv.log\n",
    "# real    1m6,024s\n",
    "# user    0m35,417s\n",
    "# sys     0m24,186s\n",
    "```\n",
    "\n",
    "And look into the first data lines, e.g.\n",
    "```bash\n",
    "head ../data/Meise_doi-10.15468-dl.ax9zkh/occurrence_recordedBy_eventDate_occurrenceIDs_20230830_parsed.tsv | column --table --separator $'\\t'\n",
    "# … you could get something like:\n",
    "# family     given  suffix  particle  dropping_particle  nick  appellation  title  occurrenceID_count  occurrenceID_firstsample                                  eventDate_mean           eventDate_min            eventDate_max\n",
    "# Azofeifa   A.                                                                    2                   https://herbarium.bgbm.org/object/B200211416              1998-04-24 12:00:00.000  1998-03-10 00:00:00.000  1998-06-09 00:00:00.000\n",
    "# A. Cano    E.                                                                    1                   https://herbarium.bgbm.org/object/B100699397              2008-06-05 00:00:00.000  2008-06-05 00:00:00.000  2008-06-05 00:00:00.000\n",
    "# Selmons    Ad                                                                    1                   https://herbarium.bgbm.org/object/B100379213              1917-07-01 00:00:00.000  1917-07-01 00:00:00.000  1917-07-01 00:00:00.000\n",
    "# Aaronsohn  A.                                                                    1                   https://herbarium.bgbm.org/object/B100379341              1908-06-20 00:00:00.000  1908-06-20 00:00:00.000  1908-06-20 00:00:00.000\n",
    "# Ani        H.             Abbas al                                               1                   http://id.snsb.info/snsb/collection/462713/563871/241553  1964-11-18 00:00:00.000  1964-11-18 00:00:00.000  1964-11-18 00:00:00.000\n",
    "# Abbe       L.B.                                                                  1                   https://herbarium.bgbm.org/object/BGT0003826              1960-03-18 00:00:00.000  1960-03-18 00:00:00.000  1960-03-18 00:00:00.000\n",
    "# Abbe       E.C.                                                                  1                   https://herbarium.bgbm.org/object/BGT0003826              1960-03-18 00:00:00.000  1960-03-18 00:00:00.000  1960-03-18 00:00:00.000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3fcbe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
